{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Importing Data Cleaning and Merging it.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "people_df = pd.read_csv(r\"C:\\Users\\DELL\\Desktop\\Projects\\DataScience\\AI-powered-Resume-Builder-and-Reviewer\\data\\54k Resume dataset (structured)\\01_people.csv\")\n",
    "abilities_df = pd.read_csv(r\"C:\\Users\\DELL\\Desktop\\Projects\\DataScience\\AI-powered-Resume-Builder-and-Reviewer\\data\\54k Resume dataset (structured)\\02_abilities.csv\")\n",
    "education_df = pd.read_csv(r\"C:\\Users\\DELL\\Desktop\\Projects\\DataScience\\AI-powered-Resume-Builder-and-Reviewer\\data\\54k Resume dataset (structured)\\03_education.csv\")\n",
    "skills_df = pd.read_csv(r\"C:\\Users\\DELL\\Desktop\\Projects\\DataScience\\AI-powered-Resume-Builder-and-Reviewer\\data\\54k Resume dataset (structured)\\06_skills.csv\")\n",
    "experience_df = pd.read_csv(r\"C:\\Users\\DELL\\Desktop\\Projects\\DataScience\\AI-powered-Resume-Builder-and-Reviewer\\data\\54k Resume dataset (structured)\\04_experience.csv\")\n",
    "person_skill_df = pd.read_csv(r\"C:\\Users\\DELL\\Desktop\\Projects\\DataScience\\AI-powered-Resume-Builder-and-Reviewer\\data\\54k Resume dataset (structured)\\05_person_skills.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Abilities CSV</h3>\n",
    "<p>The Data is Structured like multiple repeated rows with skills of individual People. People are identified by Person_id(primary Key)\n",
    "we will be keeping only first 5000 people for our project the dataset has like 50000+ people with thier data in it</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "abilities_aggregated = abilities_df.groupby('person_id')['ability'].apply(lambda x: ', '.join(x)).reset_index()\n",
    "\n",
    "# Save the aggregated data to a new CSV\n",
    "abilities_aggregated = abilities_aggregated.head(4999)\n",
    "abilities_aggregated.to_csv('02_abilities.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>People CSV</h3>\n",
    "<p>we will be removing the unnecsary columns from this csv which are email, linkdein and phone which are at average 90% null and we dont need them in our project</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns removed and cleaned file saved as '01_people_cleaned.csv'\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = ['email', 'phone', 'linkedin']\n",
    "df_cleaned = people_df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "df_cleaned = df_cleaned.head(5000)\n",
    "df_cleaned.to_csv('01_people.csv', index=False)\n",
    "\n",
    "\n",
    "print(\"Columns removed and cleaned file saved as '01_people_cleaned.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Education CSV</h3>\n",
    "<p>There are 5 columns person_id, institution, program, start_date and location, we will be removing start_date and Location since we dont need them. we will also be joining multiple person_id's rows.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education data has been merged and cleaned.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Merge the education data into one row per person_id, combining all institutions and programs\n",
    "df_education_merged = education_df.groupby('person_id').agg({\n",
    "    'institution': lambda x: ', '.join(x.dropna().unique()),  # Concatenate unique institutions\n",
    "    'program': lambda x: ', '.join(x.dropna().unique()),      # Concatenate unique programs\n",
    "}).reset_index()\n",
    "\n",
    "df_education_merged = df_education_merged.head(5000)\n",
    "# Save the cleaned and merged data to a new CSV file\n",
    "df_education_merged.to_csv('03_education.csv', index=False)\n",
    "\n",
    "\n",
    "print(\"Education data has been merged and cleaned.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Experience CSV</h3>\n",
    "<p>So this one needs more work than any other. we will first merge multiple person_id rows into 1, than we will calculate the years a person worked for, if missing we will add zero instead. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Ensure that 'title' and 'firm' columns are treated as strings\n",
    "experience_df['title'] = experience_df['title'].fillna('').astype(str)\n",
    "experience_df['firm'] = experience_df['firm'].fillna('').astype(str)\n",
    "\n",
    "# Convert start_date and end_date to datetime, coercing any errors\n",
    "experience_df['start_date'] = pd.to_datetime(experience_df['start_date'], errors='coerce')\n",
    "experience_df['end_date'] = pd.to_datetime(experience_df['end_date'], errors='coerce')\n",
    "\n",
    "# Fill missing end_date values with the current date\n",
    "experience_df['end_date'].fillna(datetime.now(), inplace=True)\n",
    "\n",
    "# Calculate the duration in years (difference between start and end date)\n",
    "experience_df['duration_years'] = (experience_df['end_date'] - experience_df['start_date']).dt.days / 365.25\n",
    "\n",
    "# Group by 'person_id' and aggregate data\n",
    "df_experience_grouped = experience_df.groupby('person_id').agg({\n",
    "    'title': ' '.join,  # Concatenate job titles for each person\n",
    "    'firm': ' '.join,   # Concatenate firm names for each person\n",
    "    'start_date': 'min',  # Keep earliest start date\n",
    "    'end_date': 'max',    # Keep latest end date\n",
    "    'duration_years': 'sum'  # Sum the durations for all jobs\n",
    "}).reset_index()\n",
    "\n",
    "# Save the cleaned and grouped experience data to a new CSV file\n",
    "df_experience_grouped = df_experience_grouped.head(5000)\n",
    "df_experience_grouped.to_csv('04_experience_grouped.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Load your 04_experience dataset\n",
    "df = pd.read_csv('C:/Users/DELL/Desktop/Projects/DataScience/AI-powered-Resume-Builder-and-Reviewer/data/Preprocessing/04_experience_cleaned.csv')\n",
    "\n",
    "# Fill missing end dates with today's date for entries with 0.0 duration\n",
    "current_date = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Replace empty or None End Dates with today's date\n",
    "df['end_date'].fillna(current_date, inplace=True)\n",
    "\n",
    "# Ensure the columns 'Start Date' and 'End Date' are in datetime format (removing time part)\n",
    "df['start_date'] = pd.to_datetime(df['start_date']).dt.date\n",
    "df['end_date'] = pd.to_datetime(df['end_date']).dt.date\n",
    "\n",
    "# Recalculate the duration for those entries that have missing or invalid end dates\n",
    "df['Calculated Duration'] = (pd.to_datetime(df['end_date']) - pd.to_datetime(df['start_date'])).dt.days / 365\n",
    "\n",
    "# Optionally, update the duration for rows with original 0.0 duration values\n",
    "df.loc[df['Calculated Duration'] == 0.0, 'Calculated Duration'] = (pd.to_datetime(df['end_date']) - pd.to_datetime(df['start_date'])).dt.days / 365\n",
    "\n",
    "# Handle NaN or infinite values in the 'Calculated Duration' column\n",
    "df['Calculated Duration'].fillna(0, inplace=True)  # Replace NaN with 0 (or another default value)\n",
    "df['Calculated Duration'] = df['Calculated Duration'].replace([float('inf'), -float('inf')], 0)  # Replace infinite values with 0\n",
    "\n",
    "# Round the 'Calculated Duration' to the nearest whole number (years) and convert to integer\n",
    "df['Calculated Duration'] = df['Calculated Duration'].round().astype(int)\n",
    "\n",
    "# Drop the 'Start Date', 'End Date', and any other columns related to time\n",
    "df.drop(columns=['start_date', 'end_date', 'duration_years'], inplace=True)\n",
    "\n",
    "# Save the updated DataFrame back to a CSV file if necessary\n",
    "df.to_csv('C:/Users/DELL/Desktop/Projects/DataScience/AI-powered-Resume-Builder-and-Reviewer/data/Preprocessing/04_experience.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Person Skills CSV</h3>\n",
    "<p>So this one needs more work than any other. we will first merge multiple person_id rows into 1, than we will calculate the years a person worked for, if missing we will add zero instead. </p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
